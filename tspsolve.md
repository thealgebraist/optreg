Skip to content
Chat history

You said:
what is the most common lp based solution for optimal tsp solving
ChatGPT said:
For exact (optimal) TSP solving, the most widely-used LP-based approach is:

ğŸ‘‰ Branch-and-Cut built on the DFJ (subtour-elimination) LP formulation
Hereâ€™s what that means in practice:

Start with an LP relaxation of the TSP:

Use the Dantzigâ€“Fulkersonâ€“Johnson (DFJ) formulation.

Variables indicate whether each edge is in the tour.

Degree constraints ensure 2 edges meet at every city.

Subtour-elimination constraints (SECs) are initially omitted (too many to list explicitly).

Solve the LP, then:

If the solution has subtours, detect them and

add violated SECs as cutting planes (also add stronger families like comb, blossom, clique-tree inequalities, etc.).

Repeat until no violated cuts remain.

If the resulting LP solution is still fractional, apply branch-and-bound â€” giving:

âœ Branch-and-Cut
This is the strategy used by top TSP solvers such as Concorde. Itâ€™s the workhorse method that scales best for exact solutions.

Related notes
The Heldâ€“Karp bound (1-tree/Lagrangian relaxation) is often used to strengthen the LP and guide branching â€” but the core framework is still branch-and-cut.

The MTZ formulation (Millerâ€“Tuckerâ€“Zemlin) is also LP-based but produces far weaker relaxations and is rarely used for large, optimal TSP solving.

TL;DR
Most common LP-based optimal TSP method:

DFJ subtour-elimination formulation + cutting planes + branch-and-bound = Branch-and-Cut.

If youâ€™d like, I can sketch the DFJ LP, show how cuts are generated, or compare it with Heldâ€“Karp and MTZ.

You said:
can it be improved
ChatGPT said:
Short answer: yes â€” but only at the margins.
The branch-and-cut (DFJ + cutting planes) framework is already extremely mature, and most â€œimprovementsâ€ today are refinements inside that framework rather than brand-new ideas.

Below is a practical map of where LP-based TSP solving has been improved â€” and where the limits are.

âœ… Proven ways branch-and-cut has been improved
1ï¸âƒ£ Much stronger cutting planes (polyhedral work)
Concordeâ€™s success came largely from decades of discovering and implementing families of inequalities:

comb, 2-matching, blossom, clique-tree

path, domino-parity cuts

lifted subtour inequalities

problem-specific cuts (e.g., Euclidean TSP geometric cuts)

The improvements here continue â€” but they are incremental and highly technical.

2ï¸âƒ£ Better separation algorithms
Finding violated cuts quickly is as important as the cuts themselves. Modern improvements include:

heuristic separation before exact separation

prioritizing â€œcheap but effectiveâ€ cuts

dynamically learning which cuts pay off on a given instance

This reduces LP solve time and branch-and-bound depth.

3ï¸âƒ£ Integration with strong relaxations
LP bounds can be strengthened by combining:

Heldâ€“Karp 1-tree / Lagrangian relaxation

dual ascent methods

sometimes even SDP or spectral bounds (costly but occasionally useful)

These can tighten the LP before branching.

4ï¸âƒ£ Primal heuristics inside the LP search
While solving the LP tree, solvers inject good tours:

Linâ€“Kernighan (LK/LKH)

local improvement / patching heuristics

random restarts guided by LP solutions

Good incumbents massively shrink the search tree.

5ï¸âƒ£ Cutting-plane management
Too many cuts can hurt. Modern solvers:

age and delete inactive cuts

avoid adding weak or redundant ones

reorder solves to preserve warm starts

This gives big practical wins.

6ï¸âƒ£ Parallelization and engineering
Better numerical stability, caching, memory layouts, and parallel separation/LP solves all matter in practice.

ğŸš§ Alternatives that sound better but rarely beat branch-and-cut
âŒ MTZ (Millerâ€“Tuckerâ€“Zemlin)
Easy to write but weak bounds â†’ scales poorly.

âš ï¸ Branch-and-price / column generation
Useful for routing problems with side constraints (VRP, time windows),
but for pure TSP, edge-based DFJ + cuts remains stronger.

âš ï¸ SDP relaxations
Beautiful theory, but solving SDPs is too expensive at scale.

âš ï¸ â€œNeuralâ€ or metaheuristic-driven exact solvers
Great heuristics, but they rarely improve optimal LP search.

ğŸ“Œ The realistic conclusion
LP-based optimal TSP solving can still be improved â€” but mostly through smarter cuts, separation heuristics, and engineering.

Breakthroughs tend to be subtle polyhedral insights, not entirely new frameworks.

Concorde (and successors like ongoing research solvers) are still essentially DFJ + very advanced branch-and-cut, and they remain state-of-the-art.

If youâ€™re curious, I can go deeper into any of these:
show the DFJ LP and where each improvement plugs in

compare Heldâ€“Karp vs DFJ numerically

sketch a simple branch-and-cut implementation

discuss why MTZ is weak

look at specific research directions still open

Just tell me!

No file chosenNo file chosen
ChatGPT can make mistakes. Check important info. See Cookie Preferences.
